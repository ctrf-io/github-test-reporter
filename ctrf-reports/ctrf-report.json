{
  "results": {
    "tool": {
      "name": "jest"
    },
    "summary": {
      "tests": 10,
      "passed": 5,
      "failed": 2,
      "pending": 1,
      "skipped": 1,
      "other": 1,
      "start": 1722511783500,
      "stop": 1722519283500
    },
    "tests": [
      {
        "name": "should be able to login",
        "status": "passed",
        "duration": 1200,
        "filePath": "tests/login.test.ts",
        "suite": "login.test.ts > login"
      },
      {
        "name": "should display title",
        "status": "failed",
        "duration": 800,
        "message": "\u001b[31mTimed out 5000ms waiting for \u001b[39m\u001b[2mexpect(\u001b[22m\u001b[31mlocator\u001b[39m\u001b[2m).\u001b[22mtoHaveTitle\u001b[2m(\u001b[22m\u001b[32mexpected\u001b[39m\u001b[2m)\u001b[22m\n\nLocator: locator(':root')\nExpected pattern: \u001b[32m/Playwrc cight/\u001b[39m\nReceived string:  \u001b[31m\"Fast and reliable end-to-end testing for modern web apps | Playwright\"\u001b[39m\nCall log:\n  \u001b[2m- expect.toHaveTitle with timeout 5000ms\u001b[22m\n\u001b[2m  - waiting for locator(':root')\u001b[22m\n\u001b[2m  -   locator resolved to <html lang=\"en\" dir=\"ltr\" data-theme=\"light\" data-has-…>…</html>\u001b[22m\n\u001b[2m  -   unexpected value \"Fast and reliable end-to-end testing for modern web apps | Playwright\"\u001b[22m\n",
        "trace": "ProfileTest.js:45",
        "ai": "The test failed because the expected page title did not match the actual title within the specified 5000ms timeout. The test was looking for a title matching the pattern '/Playwrc cight/', but received 'Fast and reliable end-to-end testing for modern web apps | Playwright' instead. \n\nTo resolve this, you should verify if the page title in your application is correct. There might be a typo in the expected title pattern in your test, which should be corrected to match the actual title. Alternatively, if the page takes longer to load, consider increasing the timeout duration in your test to allow more time for the title to appear.",
        "filePath": "tests/login.test.ts",
        "suite": "login.test.ts > profile"
      },
      {
        "name": "should be able to update profile",
        "status": "passed",
        "duration": 1200,
        "flaky": true,
        "retries": 2,
        "filePath": "tests/login.test.ts",
        "suite": "login.test.ts > profile"
      },
      {
        "name": "should be able to logout",
        "status": "skipped",
        "duration": 0,
        "filePath": "tests/login.test.ts",
        "suite": "login.test.ts > login"
      },
      {
        "name": "should validate user settings",
        "status": "passed",
        "duration": 1100,
        "filePath": "tests/settings.test.ts",
        "suite": "settings.test.ts > settings"
      },
      {
        "name": "should fail to update profile on network failure",
        "status": "failed",
        "duration": 900,
        "message": "Network Timeout",
        "trace": "ProfileUpdateTest.js:60",
        "filePath": "tests/network.test.ts",
        "suite": "network.test.ts > network",
        "ai": "The test failed because of a \"Network Timeout\" error, as indicated in the error message. The stack trace points to line 60 in the file ProfileUpdateTest.js. This suggests that the test was designed to simulate a network failure during a profile update, but it actually encountered a real network timeout. To resolve this issue, you should check the network configuration in your test environment to ensure it's correctly set up to simulate the desired network conditions. Also, verify that the timeout settings in your test code are appropriate for the expected network behavior."
      },
      {
        "name": "should load user data",
        "status": "pending",
        "duration": 0
      },
      {
        "name": "should handle session timeouts",
        "status": "passed",
        "duration": 950,
        "flaky": true,
        "retries": 1,
        "filePath": "tests/network.test.ts",
        "suite": "network.test.ts > network"
      },
      {
        "name": "should clean up user session on logout",
        "status": "other",
        "duration": 1050,
        "filePath": "tests/network.test.ts",
        "suite": "network.test.ts > network"
      },
      {
        "name": "should allow user to change password",
        "status": "passed",
        "duration": 1300,
        "flaky": true,
        "retries": 3,
        "filePath": "tests/network.test.ts",
        "suite": "network.test.ts > network"
      }
    ],
    "extra": {
      "ai": "The test suite experienced failures due to issues related to timing and network configuration. The first test failed because the expected page title did not match the actual title within the specified timeout, suggesting a potential mismatch in the expected title pattern or insufficient timeout duration. The second test encountered a real network timeout instead of the simulated failure it was designed to test, indicating problems with the network setup or timeout settings in the test environment. These failures point to a need for reviewing and adjusting both the expected outcomes and the test environment configurations to better align with actual application behavior and network conditions.",
      "aiSummary": {
        "summary": "Three related test failures in the `addFooterDisplayFlags` function reveal inconsistent logic when handling the `includeFlakyReportAllFooter` flag across different flaky test scenarios with previous suite results. Two tests expect the flag to be `false` but receive `true`, while one expects `true` but receives `false`. These are not intermittent flakiness issues but consistent logic errors that have affected approximately 27% of test runs.",
        "code_issues": "• The **addFooterDisplayFlags** function contains contradictory or inverted conditional logic when evaluating whether to set `includeFlakyReportAllFooter` based on flaky test presence across runs and previous results. The function appears to be setting the flag to the opposite of the expected value in multiple scenarios involving flaky test detection with previous suite results.\n• Logic for determining when flaky tests exist \"across all runs\" versus when they don't is either inverted or missing proper condition checks, causing the flag to be enabled when it should be disabled and vice versa in different test scenarios.\n• The combined scenario handling (flaky tests in current AND across all runs) is incorrectly evaluating conditions when merging current results with previous historical data, failing to properly suppress the footer flag when flaky tests are detected.",
        "timeout_issues": "",
        "application_issues": "• The test suite shows a consistent 27% failure rate across 52 runs for these specific flag-setting scenarios, indicating a persistent, reproducible bug rather than environmental or timing-related flakiness.",
        "recommendations": "• Review the **addFooterDisplayFlags** function's conditional logic for setting `includeFlakyReportAllFooter`, specifically the conditions that check for flaky tests across all runs and in combination with previous results.\n• Verify all boolean comparisons and negations in the flaky test detection logic to ensure they are not inverted or contradictory.\n• Add explicit unit tests or debug traces to validate the flaky test count calculations when previous results are included to ensure accurate detection of flaky tests across runs.\n• Ensure the logic correctly distinguishes between three scenarios: (1) flaky tests exist across all runs with previous results, (2) no flaky tests exist across all runs with previous results, and (3) combined current and historical flaky tests, setting the flag appropriately for each case."
      }
    }
  }
}
